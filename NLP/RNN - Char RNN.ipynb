{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 글자 단위 RNN 언어 모델(Char RNNLM)\n",
    "- https://wikidocs.net/48649\n",
    "- 입출력의 단위를 단어 레벨(word-level)에서 글자 레벨(character-level)로 변경하여 RNN을 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:22:38.202357Z",
     "start_time": "2020-09-10T12:22:38.196340Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "- '이상한 나라의 앨리스(Alice’s Adventures in Wonderland)'라는 소설을 다운로드\n",
    "- 다운로드 링크 : http://www.gutenberg.org/files/11/11-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T11:54:02.849490Z",
     "start_time": "2020-09-10T11:54:01.409209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
       " 'this ebook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  you may copy it, give it away or',\n",
       " 're-use it under the terms of the project gutenberg license included',\n",
       " 'with this ebook or online at www.gutenberg.org']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
    "f = open('11-0.txt', 'rb')\n",
    "lines=[]\n",
    "for line in f: \n",
    "    line=line.strip() # strip()을 통해 \\r, \\n을 제거한다.\n",
    "    line=line.lower() \n",
    "    line=line.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
    "    if len(line) > 0:\n",
    "        lines.append(line)\n",
    "f.close()\n",
    "\n",
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T11:55:15.161929Z",
     "start_time": "2020-09-10T11:55:15.158574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 길이/총 글자의 개수: 159612\n"
     ]
    }
   ],
   "source": [
    "text = \" \".join(lines)\n",
    "print(f\"텍스트의 길이/총 글자의 개수: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어가 훈련 데이터일 때 대부분의 경우에서 글자 집합의 크기가 단어 집합을 사용했을 경우보다 집합의 크기가 현저히 작다는 특징이 있습니다. 아무리 훈련 코퍼스에 수십만 개 이상의 많은 영어 단어가 존재한다고 하더라도, 영어 단어를 표현하기 위해서 글자 집합에 포함되는 글자는 26개의 알파벳뿐이기 때문입니다. 만약 훈련 데이터의 알파벳이 대, 소문자가 구분된 상태라고 하더라도 모든 영어 단어는 총 52개의 알파벳으로 표현 가능합니다.\n",
    "\n",
    "어떤 방대한 양의 텍스트라도 집합의 크기를 적게 가져갈 수 있다는 것은 구현과 테스트를 굉장히 쉽게 할 수 있다는 이점을 가지므로, RNN의 동작 메커니즘 이해를 위한 토이 프로젝트로 굉장히 많이 사용됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T11:56:04.402376Z",
     "start_time": "2020-09-10T11:56:04.396823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자 집합의 크기:57\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted(list(set(text)))\n",
    "vocab_size=len(char_vocab)\n",
    "print(f\"글자 집합의 크기:{vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T11:58:43.079655Z",
     "start_time": "2020-09-10T11:58:43.076493Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '@': 27, '[': 28, ']': 29, '_': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = {c:i for i, c in enumerate(char_vocab)}\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T11:59:28.717444Z",
     "start_time": "2020-09-10T11:59:28.713198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '@', 28: '[', 29: ']', 30: '_', 31: 'a', 32: 'b', 33: 'c', 34: 'd', 35: 'e', 36: 'f', 37: 'g', 38: 'h', 39: 'i', 40: 'j', 41: 'k', 42: 'l', 43: 'm', 44: 'n', 45: 'o', 46: 'p', 47: 'q', 48: 'r', 49: 's', 50: 't', 51: 'u', 52: 'v', 53: 'w', 54: 'x', 55: 'y', 56: 'z'}\n"
     ]
    }
   ],
   "source": [
    "index_to_char = {i:c for c, i in char_to_index.items()}\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:11:27.943036Z",
     "start_time": "2020-09-10T12:11:27.939495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 샘플의 수: 2660\n"
     ]
    }
   ],
   "source": [
    "# text 문자열로부터 다수의 문장 샘플들로 분리\n",
    "seq_length = 60 # 문장의 길이\n",
    "n_samples = int(np.floor((len(text) - 1) / seq_length))\n",
    "print(f\"문장 샘플의 수: {n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:18:43.150263Z",
     "start_time": "2020-09-10T12:18:43.109027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2660, 2660)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(n_samples):\n",
    "    x_sample = text[i*seq_length:(i+1)*seq_length]\n",
    "    x_encoded = [char_to_index[c] for c in x_sample]\n",
    "    x_train.append(x_encoded)\n",
    "    \n",
    "    y_sample = text[i*seq_length+1:(i+1)*seq_length+1]\n",
    "    y_encoded = [char_to_index[c] for c in y_sample]\n",
    "    y_train.append(y_encoded)\n",
    "len(x_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:18:43.686266Z",
     "start_time": "2020-09-10T12:18:43.640570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2660, 60, 57), (2660, 60, 57))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = to_categorical(x_train)\n",
    "y_train = to_categorical(y_train)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:36:56.577399Z",
     "start_time": "2020-09-10T12:36:56.102093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 256)         321536    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 256)         525312    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 57)          14649     \n",
      "=================================================================\n",
      "Total params: 861,497\n",
      "Trainable params: 861,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(None, x_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation=\"softmax\")))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:42:43.520868Z",
     "start_time": "2020-09-10T12:42:43.482530Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T13:15:30.489092Z",
     "start_time": "2020-09-10T12:43:07.867465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2660 samples\n",
      "Epoch 1/80\n",
      "2660/2660 - 22s - loss: 3.0684 - accuracy: 0.1830\n",
      "Epoch 2/80\n",
      "2660/2660 - 20s - loss: 2.7321 - accuracy: 0.2480\n",
      "Epoch 3/80\n",
      "2660/2660 - 21s - loss: 2.3909 - accuracy: 0.3278\n",
      "Epoch 4/80\n",
      "2660/2660 - 21s - loss: 2.2405 - accuracy: 0.3654\n",
      "Epoch 5/80\n",
      "2660/2660 - 21s - loss: 2.1263 - accuracy: 0.3929\n",
      "Epoch 6/80\n",
      "2660/2660 - 21s - loss: 2.0399 - accuracy: 0.4133\n",
      "Epoch 7/80\n",
      "2660/2660 - 21s - loss: 1.9688 - accuracy: 0.4321\n",
      "Epoch 8/80\n",
      "2660/2660 - 21s - loss: 1.9077 - accuracy: 0.4468\n",
      "Epoch 9/80\n",
      "2660/2660 - 21s - loss: 1.8500 - accuracy: 0.4634\n",
      "Epoch 10/80\n",
      "2660/2660 - 21s - loss: 1.7999 - accuracy: 0.4774\n",
      "Epoch 11/80\n",
      "2660/2660 - 21s - loss: 1.7558 - accuracy: 0.4897\n",
      "Epoch 12/80\n",
      "2660/2660 - 21s - loss: 1.7118 - accuracy: 0.5010\n",
      "Epoch 13/80\n",
      "2660/2660 - 21s - loss: 1.6704 - accuracy: 0.5115\n",
      "Epoch 14/80\n",
      "2660/2660 - 21s - loss: 1.6323 - accuracy: 0.5219\n",
      "Epoch 15/80\n",
      "2660/2660 - 21s - loss: 1.5947 - accuracy: 0.5316\n",
      "Epoch 16/80\n",
      "2660/2660 - 21s - loss: 1.5621 - accuracy: 0.5404\n",
      "Epoch 17/80\n",
      "2660/2660 - 21s - loss: 1.5264 - accuracy: 0.5494\n",
      "Epoch 18/80\n",
      "2660/2660 - 21s - loss: 1.4936 - accuracy: 0.5582\n",
      "Epoch 19/80\n",
      "2660/2660 - 21s - loss: 1.4619 - accuracy: 0.5681\n",
      "Epoch 20/80\n",
      "2660/2660 - 21s - loss: 1.4304 - accuracy: 0.5764\n",
      "Epoch 21/80\n",
      "2660/2660 - 22s - loss: 1.4018 - accuracy: 0.5844\n",
      "Epoch 22/80\n",
      "2660/2660 - 21s - loss: 1.3730 - accuracy: 0.5931\n",
      "Epoch 23/80\n",
      "2660/2660 - 21s - loss: 1.3419 - accuracy: 0.6014\n",
      "Epoch 24/80\n",
      "2660/2660 - 21s - loss: 1.3147 - accuracy: 0.6098\n",
      "Epoch 25/80\n",
      "2660/2660 - 22s - loss: 1.2841 - accuracy: 0.6180\n",
      "Epoch 26/80\n",
      "2660/2660 - 22s - loss: 1.2560 - accuracy: 0.6267\n",
      "Epoch 27/80\n",
      "2660/2660 - 22s - loss: 1.2265 - accuracy: 0.6351\n",
      "Epoch 28/80\n",
      "2660/2660 - 22s - loss: 1.1984 - accuracy: 0.6442\n",
      "Epoch 29/80\n",
      "2660/2660 - 22s - loss: 1.1722 - accuracy: 0.6512\n",
      "Epoch 30/80\n",
      "2660/2660 - 22s - loss: 1.1417 - accuracy: 0.6599\n",
      "Epoch 31/80\n",
      "2660/2660 - 22s - loss: 1.1142 - accuracy: 0.6684\n",
      "Epoch 32/80\n",
      "2660/2660 - 22s - loss: 1.0851 - accuracy: 0.6776\n",
      "Epoch 33/80\n",
      "2660/2660 - 22s - loss: 1.0560 - accuracy: 0.6854\n",
      "Epoch 34/80\n",
      "2660/2660 - 22s - loss: 1.0275 - accuracy: 0.6936\n",
      "Epoch 35/80\n",
      "2660/2660 - 22s - loss: 0.9986 - accuracy: 0.7031\n",
      "Epoch 36/80\n",
      "2660/2660 - 22s - loss: 0.9664 - accuracy: 0.7133\n",
      "Epoch 37/80\n",
      "2660/2660 - 22s - loss: 0.9386 - accuracy: 0.7215\n",
      "Epoch 38/80\n",
      "2660/2660 - 22s - loss: 0.9117 - accuracy: 0.7297\n",
      "Epoch 39/80\n",
      "2660/2660 - 22s - loss: 0.8828 - accuracy: 0.7384\n",
      "Epoch 40/80\n",
      "2660/2660 - 22s - loss: 0.8592 - accuracy: 0.7459\n",
      "Epoch 41/80\n",
      "2660/2660 - 22s - loss: 0.8255 - accuracy: 0.7570\n",
      "Epoch 42/80\n",
      "2660/2660 - 22s - loss: 0.7983 - accuracy: 0.7651\n",
      "Epoch 43/80\n",
      "2660/2660 - 22s - loss: 0.7679 - accuracy: 0.7749\n",
      "Epoch 44/80\n",
      "2660/2660 - 22s - loss: 0.7479 - accuracy: 0.7811\n",
      "Epoch 45/80\n",
      "2660/2660 - 22s - loss: 0.7200 - accuracy: 0.7894\n",
      "Epoch 46/80\n",
      "2660/2660 - 22s - loss: 0.6888 - accuracy: 0.8003\n",
      "Epoch 47/80\n",
      "2660/2660 - 22s - loss: 0.6631 - accuracy: 0.8091\n",
      "Epoch 48/80\n",
      "2660/2660 - 22s - loss: 0.6460 - accuracy: 0.8133\n",
      "Epoch 49/80\n",
      "2660/2660 - 22s - loss: 0.6154 - accuracy: 0.8246\n",
      "Epoch 50/80\n",
      "2660/2660 - 22s - loss: 0.5915 - accuracy: 0.8315\n",
      "Epoch 51/80\n",
      "2660/2660 - 21s - loss: 0.5678 - accuracy: 0.8402\n",
      "Epoch 52/80\n",
      "2660/2660 - 22s - loss: 0.5449 - accuracy: 0.8469\n",
      "Epoch 53/80\n",
      "2660/2660 - 22s - loss: 0.5268 - accuracy: 0.8519\n",
      "Epoch 54/80\n",
      "2660/2660 - 22s - loss: 0.5113 - accuracy: 0.8553\n",
      "Epoch 55/80\n",
      "2660/2660 - 22s - loss: 0.4833 - accuracy: 0.8671\n",
      "Epoch 56/80\n",
      "2660/2660 - 22s - loss: 0.4640 - accuracy: 0.8725\n",
      "Epoch 57/80\n",
      "2660/2660 - 22s - loss: 0.4497 - accuracy: 0.8768\n",
      "Epoch 58/80\n",
      "2660/2660 - 22s - loss: 0.4283 - accuracy: 0.8838\n",
      "Epoch 59/80\n",
      "2660/2660 - 22s - loss: 0.4118 - accuracy: 0.8894\n",
      "Epoch 60/80\n",
      "2660/2660 - 22s - loss: 0.3868 - accuracy: 0.8982\n",
      "Epoch 61/80\n",
      "2660/2660 - 63s - loss: 0.3730 - accuracy: 0.9023\n",
      "Epoch 62/80\n",
      "2660/2660 - 98s - loss: 0.3597 - accuracy: 0.9059\n",
      "Epoch 63/80\n",
      "2660/2660 - 93s - loss: 0.3453 - accuracy: 0.9105\n",
      "Epoch 64/80\n",
      "2660/2660 - 52s - loss: 0.3313 - accuracy: 0.9149\n",
      "Epoch 65/80\n",
      "2660/2660 - 22s - loss: 0.3322 - accuracy: 0.9124\n",
      "Epoch 66/80\n",
      "2660/2660 - 22s - loss: 0.3049 - accuracy: 0.9226\n",
      "Epoch 67/80\n",
      "2660/2660 - 22s - loss: 0.2865 - accuracy: 0.9297\n",
      "Epoch 68/80\n",
      "2660/2660 - 22s - loss: 0.2749 - accuracy: 0.9322\n",
      "Epoch 69/80\n",
      "2660/2660 - 22s - loss: 0.2566 - accuracy: 0.9387\n",
      "Epoch 70/80\n",
      "2660/2660 - 22s - loss: 0.2494 - accuracy: 0.9402\n",
      "Epoch 71/80\n",
      "2660/2660 - 22s - loss: 0.2424 - accuracy: 0.9422\n",
      "Epoch 72/80\n",
      "2660/2660 - 22s - loss: 0.2335 - accuracy: 0.9440\n",
      "Epoch 73/80\n",
      "2660/2660 - 22s - loss: 0.2303 - accuracy: 0.9445\n",
      "Epoch 74/80\n",
      "2660/2660 - 22s - loss: 0.2272 - accuracy: 0.9448\n",
      "Epoch 75/80\n",
      "2660/2660 - 22s - loss: 0.2244 - accuracy: 0.9451\n",
      "Epoch 76/80\n",
      "2660/2660 - 22s - loss: 0.2200 - accuracy: 0.9457\n",
      "Epoch 77/80\n",
      "2660/2660 - 22s - loss: 0.2060 - accuracy: 0.9500\n",
      "Epoch 78/80\n",
      "2660/2660 - 22s - loss: 0.1911 - accuracy: 0.9545\n",
      "Epoch 79/80\n",
      "2660/2660 - 22s - loss: 0.1832 - accuracy: 0.9569\n",
      "Epoch 80/80\n",
      "2660/2660 - 22s - loss: 0.1728 - accuracy: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f82d2e5b908>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=80, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T13:18:28.746310Z",
     "start_time": "2020-09-10T13:18:28.738063Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_generation(model, length):\n",
    "    ix = [np.random.randint(vocab_size)] # 글자에 대한 랜덤 인덱스 생성\n",
    "    y_char = [index_to_char[ix[-1]]]\n",
    "    print(f\"{ix[-1]}번 글자 {y_char[-1]}로 예측 시작\")\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    \n",
    "    for i in range(length):\n",
    "        X[0][i][ix[-1]] = 1\n",
    "        print(index_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:,:i+1,:])[0], 1)\n",
    "        y_char.append(index_to_char[ix[-1]])\n",
    "    return \"\".join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T13:19:43.725335Z",
     "start_time": "2020-09-10T13:19:42.699750Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44번 글자 n로 예측 시작\n",
      "nd stupid for life to go on in"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nd stupid for life to go on in '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = sentence_generation(model, 30)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
