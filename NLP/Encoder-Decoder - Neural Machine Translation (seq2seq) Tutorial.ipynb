{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation (seq2seq) Tutorial\n",
    "- https://wikidocs.net/86900\n",
    "- seq2seq를 사용하여 단어 레벨(Word-level)의 기계 번역기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:56:31.214779Z",
     "start_time": "2020-10-27T12:56:26.825222Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:57:04.345507Z",
     "start_time": "2020-10-27T12:57:01.006275Z"
    }
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:58:21.611887Z",
     "start_time": "2020-10-27T12:58:21.609648Z"
    }
   },
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:58:21.827629Z",
     "start_time": "2020-10-27T12:58:21.824585Z"
    }
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:58:21.979792Z",
     "start_time": "2020-10-27T12:58:21.975928Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:30:52.263919Z",
     "start_time": "2020-10-27T13:30:52.257673Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:31:12.650724Z",
     "start_time": "2020-10-27T13:31:11.580533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n",
      "[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### integer encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:34:09.503831Z",
     "start_time": "2020-10-27T13:34:09.345586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "len(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:34:27.988617Z",
     "start_time": "2020-10-27T13:34:27.499250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 33000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
    "len(decoder_input), len(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:35:12.738047Z",
     "start_time": "2020-10-27T13:35:12.734397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4663, 프랑스어 단어 집합의 크기 : 8038\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:35:26.464655Z",
     "start_time": "2020-10-27T13:35:26.461751Z"
    }
   },
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:34:57.891126Z",
     "start_time": "2020-10-27T13:34:57.592562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33000, 8), (33000, 16), (33000, 16))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")\n",
    "encoder_input.shape, decoder_input.shape, decoder_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:35:48.983878Z",
     "start_time": "2020-10-27T13:35:48.979623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17051  5717   690 ...  3812 22903 31777]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:35:59.700853Z",
     "start_time": "2020-10-27T13:35:59.692440Z"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:36:27.055202Z",
     "start_time": "2020-10-27T13:36:27.052508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print(n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T13:36:37.841118Z",
     "start_time": "2020-10-27T13:36:37.836375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29700, 8)\n",
      "(29700, 16)\n",
      "(29700, 16)\n",
      "(3300, 8)\n",
      "(3300, 16)\n",
      "(3300, 16)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:16:35.047665Z",
     "start_time": "2020-10-29T14:16:35.020218Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:16:56.877817Z",
     "start_time": "2020-10-29T14:16:56.023534Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:17:25.859981Z",
     "start_time": "2020-10-29T14:17:25.281570Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:17:35.404882Z",
     "start_time": "2020-10-29T14:17:35.391583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     233150      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     401900      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8038)   409938      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,085,388\n",
      "Trainable params: 1,085,388\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:17:40.833806Z",
     "start_time": "2020-10-29T14:17:40.822391Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T00:15:34.599978Z",
     "start_time": "2020-10-29T14:18:13.578095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "233/233 [==============================] - 198s 849ms/step - loss: 3.1916 - acc: 0.6047 - val_loss: 1.9265 - val_acc: 0.6818\n",
      "Epoch 2/50\n",
      "233/233 [==============================] - 165s 710ms/step - loss: 1.7484 - acc: 0.7246 - val_loss: 1.6305 - val_acc: 0.7414\n",
      "Epoch 3/50\n",
      "233/233 [==============================] - 133s 569ms/step - loss: 1.5624 - acc: 0.7452 - val_loss: 1.5244 - val_acc: 0.7528\n",
      "Epoch 4/50\n",
      "233/233 [==============================] - 146s 625ms/step - loss: 1.4613 - acc: 0.7619 - val_loss: 1.4492 - val_acc: 0.7673\n",
      "Epoch 5/50\n",
      "233/233 [==============================] - 117s 501ms/step - loss: 1.3722 - acc: 0.7782 - val_loss: 1.3615 - val_acc: 0.7834\n",
      "Epoch 6/50\n",
      "233/233 [==============================] - 121s 518ms/step - loss: 1.3072 - acc: 0.7870 - val_loss: 1.3176 - val_acc: 0.7905\n",
      "Epoch 7/50\n",
      "233/233 [==============================] - 122s 522ms/step - loss: 1.2543 - acc: 0.7951 - val_loss: 1.2735 - val_acc: 0.7955\n",
      "Epoch 8/50\n",
      "233/233 [==============================] - 124s 531ms/step - loss: 1.2076 - acc: 0.8025 - val_loss: 1.2390 - val_acc: 0.8025\n",
      "Epoch 9/50\n",
      "233/233 [==============================] - 123s 529ms/step - loss: 1.1667 - acc: 0.8080 - val_loss: 1.2089 - val_acc: 0.8053\n",
      "Epoch 10/50\n",
      "233/233 [==============================] - 125s 536ms/step - loss: 1.1317 - acc: 0.8127 - val_loss: 1.1681 - val_acc: 0.8130\n",
      "Epoch 11/50\n",
      "233/233 [==============================] - 123s 527ms/step - loss: 1.1006 - acc: 0.8173 - val_loss: 1.1455 - val_acc: 0.8158\n",
      "Epoch 12/50\n",
      "233/233 [==============================] - 125s 538ms/step - loss: 1.0725 - acc: 0.8207 - val_loss: 1.1244 - val_acc: 0.8196\n",
      "Epoch 13/50\n",
      "233/233 [==============================] - 124s 533ms/step - loss: 1.0469 - acc: 0.8242 - val_loss: 1.1223 - val_acc: 0.8166\n",
      "Epoch 14/50\n",
      "233/233 [==============================] - 125s 535ms/step - loss: 1.0237 - acc: 0.8271 - val_loss: 1.0905 - val_acc: 0.8227\n",
      "Epoch 15/50\n",
      "233/233 [==============================] - 125s 535ms/step - loss: 1.0019 - acc: 0.8305 - val_loss: 1.0726 - val_acc: 0.8259\n",
      "Epoch 16/50\n",
      "233/233 [==============================] - 125s 538ms/step - loss: 0.9808 - acc: 0.8332 - val_loss: 1.0559 - val_acc: 0.8271\n",
      "Epoch 17/50\n",
      "233/233 [==============================] - 123s 529ms/step - loss: 0.9610 - acc: 0.8355 - val_loss: 1.0469 - val_acc: 0.8280\n",
      "Epoch 18/50\n",
      "233/233 [==============================] - 123s 530ms/step - loss: 0.9419 - acc: 0.8383 - val_loss: 1.0321 - val_acc: 0.8301\n",
      "Epoch 19/50\n",
      "233/233 [==============================] - 125s 536ms/step - loss: 0.9237 - acc: 0.8408 - val_loss: 1.0125 - val_acc: 0.8333\n",
      "Epoch 20/50\n",
      "233/233 [==============================] - 124s 533ms/step - loss: 0.9069 - acc: 0.8432 - val_loss: 1.0049 - val_acc: 0.8356\n",
      "Epoch 21/50\n",
      "233/233 [==============================] - 125s 536ms/step - loss: 0.8917 - acc: 0.8455 - val_loss: 0.9979 - val_acc: 0.8355\n",
      "Epoch 22/50\n",
      "233/233 [==============================] - 125s 538ms/step - loss: 0.8769 - acc: 0.8475 - val_loss: 0.9868 - val_acc: 0.8373\n",
      "Epoch 23/50\n",
      "233/233 [==============================] - 124s 532ms/step - loss: 0.8629 - acc: 0.8494 - val_loss: 0.9772 - val_acc: 0.8379\n",
      "Epoch 24/50\n",
      "233/233 [==============================] - 124s 532ms/step - loss: 0.8503 - acc: 0.8514 - val_loss: 0.9599 - val_acc: 0.8414\n",
      "Epoch 25/50\n",
      "233/233 [==============================] - 124s 532ms/step - loss: 0.8384 - acc: 0.8534 - val_loss: 0.9641 - val_acc: 0.8402\n",
      "Epoch 26/50\n",
      "233/233 [==============================] - 125s 535ms/step - loss: 0.8275 - acc: 0.8553 - val_loss: 0.9570 - val_acc: 0.8425\n",
      "Epoch 27/50\n",
      "233/233 [==============================] - 125s 536ms/step - loss: 0.8177 - acc: 0.8570 - val_loss: 0.9467 - val_acc: 0.8430\n",
      "Epoch 28/50\n",
      "233/233 [==============================] - 124s 534ms/step - loss: 0.8081 - acc: 0.8586 - val_loss: 0.9413 - val_acc: 0.8456\n",
      "Epoch 29/50\n",
      "233/233 [==============================] - 123s 529ms/step - loss: 0.7986 - acc: 0.8604 - val_loss: 0.9388 - val_acc: 0.8439\n",
      "Epoch 30/50\n",
      "233/233 [==============================] - 124s 533ms/step - loss: 0.7894 - acc: 0.8622 - val_loss: 0.9438 - val_acc: 0.8438\n",
      "Epoch 31/50\n",
      "233/233 [==============================] - 124s 533ms/step - loss: 0.7803 - acc: 0.8636 - val_loss: 0.9367 - val_acc: 0.8442\n",
      "Epoch 32/50\n",
      "233/233 [==============================] - 124s 530ms/step - loss: 0.7717 - acc: 0.8651 - val_loss: 0.9220 - val_acc: 0.8475\n",
      "Epoch 33/50\n",
      "233/233 [==============================] - 2342s 10s/step - loss: 0.7632 - acc: 0.8664 - val_loss: 0.9194 - val_acc: 0.8480\n",
      "Epoch 34/50\n",
      "233/233 [==============================] - 24054s 103s/step - loss: 0.7546 - acc: 0.8681 - val_loss: 0.9086 - val_acc: 0.8498\n",
      "Epoch 35/50\n",
      "233/233 [==============================] - 3278s 14s/step - loss: 0.7466 - acc: 0.8695 - val_loss: 0.9070 - val_acc: 0.8500\n",
      "Epoch 36/50\n",
      "233/233 [==============================] - 121s 519ms/step - loss: 0.7389 - acc: 0.8706 - val_loss: 0.9030 - val_acc: 0.8503\n",
      "Epoch 37/50\n",
      "233/233 [==============================] - 124s 534ms/step - loss: 0.7315 - acc: 0.8721 - val_loss: 0.8920 - val_acc: 0.8540\n",
      "Epoch 38/50\n",
      "233/233 [==============================] - 124s 531ms/step - loss: 0.7246 - acc: 0.8736 - val_loss: 0.9100 - val_acc: 0.8501\n",
      "Epoch 39/50\n",
      "233/233 [==============================] - 128s 549ms/step - loss: 0.7180 - acc: 0.8747 - val_loss: 0.9000 - val_acc: 0.8514\n",
      "Epoch 40/50\n",
      "233/233 [==============================] - 123s 526ms/step - loss: 0.7111 - acc: 0.8759 - val_loss: 0.8844 - val_acc: 0.8542\n",
      "Epoch 41/50\n",
      "233/233 [==============================] - 132s 565ms/step - loss: 0.7040 - acc: 0.8772 - val_loss: 0.9085 - val_acc: 0.8503\n",
      "Epoch 42/50\n",
      "233/233 [==============================] - 130s 556ms/step - loss: 0.6966 - acc: 0.8784 - val_loss: 0.8865 - val_acc: 0.8546\n",
      "Epoch 43/50\n",
      "233/233 [==============================] - 141s 603ms/step - loss: 0.6889 - acc: 0.8798 - val_loss: 0.8706 - val_acc: 0.8563\n",
      "Epoch 44/50\n",
      "233/233 [==============================] - 125s 538ms/step - loss: 0.6801 - acc: 0.8811 - val_loss: 0.8689 - val_acc: 0.8562\n",
      "Epoch 45/50\n",
      "233/233 [==============================] - 144s 618ms/step - loss: 0.6723 - acc: 0.8820 - val_loss: 0.8660 - val_acc: 0.8575\n",
      "Epoch 46/50\n",
      "233/233 [==============================] - 141s 604ms/step - loss: 0.6652 - acc: 0.8836 - val_loss: 0.8682 - val_acc: 0.8569\n",
      "Epoch 47/50\n",
      "233/233 [==============================] - 145s 621ms/step - loss: 0.6590 - acc: 0.8846 - val_loss: 0.8715 - val_acc: 0.8567\n",
      "Epoch 48/50\n",
      "233/233 [==============================] - 147s 629ms/step - loss: 0.6532 - acc: 0.8858 - val_loss: 0.8583 - val_acc: 0.8590\n",
      "Epoch 49/50\n",
      "233/233 [==============================] - 151s 649ms/step - loss: 0.6480 - acc: 0.8869 - val_loss: 0.8551 - val_acc: 0.8591\n",
      "Epoch 50/50\n",
      "233/233 [==============================] - 154s 660ms/step - loss: 0.6426 - acc: 0.8878 - val_loss: 0.8665 - val_acc: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb492c5e978>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = [encoder_input_train, decoder_input_train], \n",
    "    y = decoder_target_train,\n",
    "    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "    batch_size = 128, \n",
    "    epochs = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq 기계 번역기 동작시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
