{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SubwordTextEncoder\n",
    "- https://wikidocs.net/86792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize imdb review using SubwordTextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:45:29.500363Z",
     "start_time": "2020-10-20T12:45:29.495995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:47:23.980440Z",
     "start_time": "2020-10-20T12:46:24.285747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:47:59.851105Z",
     "start_time": "2020-10-20T12:47:46.116354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:48:00.388492Z",
     "start_time": "2020-10-20T12:47:59.852976Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:48:19.739257Z",
     "start_time": "2020-10-20T12:48:03.533005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x7fda89b71da0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:48:20.333720Z",
     "start_time": "2020-10-20T12:48:19.741678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDb_Reviews.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:54:33.793367Z",
     "start_time": "2020-10-20T12:50:47.603162Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    df[\"review\"], target_vocab_size=2**13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:57:15.823699Z",
     "start_time": "2020-10-20T12:57:15.819822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8268, 8192)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size, 2 ** 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:54:33.807007Z",
     "start_time": "2020-10-20T12:54:33.802369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.subwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:55:43.866593Z",
     "start_time": "2020-10-20T12:55:43.863038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My family and I normally do not watch local movies for the simple reason that they are poorly made, they lack the depth, and just not worth our time.<br /><br />The trailer of \"Nasaan ka man\" caught my attention, my daughter in law's and daughter's so we took time out to watch it this afternoon. The movie exceeded our expectations. The cinematography was very good, the story beautiful and the acting awesome. Jericho Rosales was really very good, so's Claudine Barretto. The fact that I despised Diether Ocampo proves he was effective at his role. I have never been this touched, moved and affected by a local movie before. Imagine a cynic like me dabbing my eyes at the end of the movie? Congratulations to Star Cinema!! Way to go, Jericho and Claudine!! [390, 410, 5, 12, 6771, 110, 33, 160, 1067, 172, 23, 1, 1340, 450, 13, 54, 28, 1653, 681, 2, 54, 813, 1, 7739, 2, 5, 56, 33, 359, 326, 166, 24, 10, 16, 10, 17, 19, 5540, 231, 37, 810, 557, 41, 5491, 213, 53, 2020, 80, 4688, 2, 80, 1413, 11, 3758, 8051, 8, 5, 1643, 8051, 8, 55, 106, 756, 102, 61, 7, 160, 15, 14, 1975, 6358, 8122, 3, 19, 27, 4752, 6602, 40, 326, 6599, 8127, 3, 19, 1633, 18, 67, 250, 2, 1, 101, 492, 5, 1, 187, 7151, 3, 3390, 5862, 200, 3680, 2183, 8, 18, 81, 67, 250, 2, 347, 8051, 8, 7638, 1172, 1214, 1597, 252, 3, 19, 314, 13, 12, 3057, 6702, 3410, 1650, 7065, 863, 1107, 8044, 3786, 44, 18, 3217, 42, 31, 809, 3, 12, 30, 140, 92, 14, 2782, 104, 2, 3993, 5, 4903, 38, 43, 4, 1067, 27, 1013, 3, 7178, 856, 50, 4, 5938, 8044, 51, 103, 1056, 4184, 150, 80, 1300, 42, 1, 226, 6, 1, 64, 87, 792, 3488, 5025, 1559, 7, 2358, 5772, 1257, 7691, 8044, 7, 591, 2, 3390, 5862, 200, 5, 7638, 922, 2654]\n"
     ]
    }
   ],
   "source": [
    "# encode\n",
    "print(df.review.values[0], tokenizer.encode(df.review.values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:56:52.469094Z",
     "start_time": "2020-10-20T12:56:52.465224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장: [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n",
      "기존 문장: It's mind-blowing to me that this film was even made.\n"
     ]
    }
   ],
   "source": [
    "sample_string = \"It's mind-blowing to me that this film was even made.\"\n",
    "\n",
    "#encode\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print (f'정수 인코딩 후의 문장: {tokenized_string}')\n",
    "\n",
    "#decode\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print(f'기존 문장: {original_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:57:50.811299Z",
     "start_time": "2020-10-20T12:57:50.807402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ----> It\n",
      "8051 ----> '\n",
      "8 ----> s \n",
      "910 ----> mind\n",
      "8057 ----> -\n",
      "2169 ----> blow\n",
      "36 ----> ing \n",
      "7 ----> to \n",
      "103 ----> me \n",
      "13 ----> that \n",
      "14 ----> this \n",
      "32 ----> film \n",
      "18 ----> was \n",
      "79 ----> even \n",
      "681 ----> made\n",
      "8058 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:58:12.614770Z",
     "start_time": "2020-10-20T12:58:12.611073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장: [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 7974, 8132, 8133, 997, 681, 8058]\n",
      "기존 문장: It's mind-blowing to me that this film was evenxyz made.\n"
     ]
    }
   ],
   "source": [
    "sample_string = \"It's mind-blowing to me that this film was evenxyz made.\"\n",
    "\n",
    "#encode\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print (f'정수 인코딩 후의 문장: {tokenized_string}')\n",
    "\n",
    "#decode\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print(f'기존 문장: {original_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:58:18.981843Z",
     "start_time": "2020-10-20T12:58:18.978333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ----> It\n",
      "8051 ----> '\n",
      "8 ----> s \n",
      "910 ----> mind\n",
      "8057 ----> -\n",
      "2169 ----> blow\n",
      "36 ----> ing \n",
      "7 ----> to \n",
      "103 ----> me \n",
      "13 ----> that \n",
      "14 ----> this \n",
      "32 ----> film \n",
      "18 ----> was \n",
      "7974 ----> even\n",
      "8132 ----> x\n",
      "8133 ----> y\n",
      "997 ----> z \n",
      "681 ----> made\n",
      "8058 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize naver review using SubwordTextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:16:58.613001Z",
     "start_time": "2020-10-22T11:16:58.605842Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:17:47.389792Z",
     "start_time": "2020-10-22T11:17:03.133895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_train.txt', <http.client.HTTPMessage at 0x7fda7fef8710>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:17:47.805880Z",
     "start_time": "2020-10-22T11:17:47.391919Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"ratings_train.txt\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:17:47.835182Z",
     "start_time": "2020-10-22T11:17:47.808298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:18:12.829839Z",
     "start_time": "2020-10-22T11:18:12.771483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149995, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how=\"any\")\n",
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:27:58.749228Z",
     "start_time": "2020-10-22T11:22:16.073834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. ', '..', '영화', '이_', '...', '의_', '는_', '도_', '다', ', ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    df[\"document\"], target_vocab_size=2**13\n",
    ")\n",
    "tokenizer.subwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:27:58.761510Z",
     "start_time": "2020-10-22T11:27:58.751209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[121,\n",
       " 312,\n",
       " 4,\n",
       " 81,\n",
       " 410,\n",
       " 304,\n",
       " 6,\n",
       " 229,\n",
       " 174,\n",
       " 225,\n",
       " 8042,\n",
       " 67,\n",
       " 108,\n",
       " 45,\n",
       " 296,\n",
       " 312,\n",
       " 1297,\n",
       " 8030,\n",
       " 977,\n",
       " 2312,\n",
       " 3860,\n",
       " 198,\n",
       " 2193,\n",
       " 630,\n",
       " 8044]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(df[\"document\"][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:28:13.793435Z",
     "start_time": "2020-10-22T11:28:13.789274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [570, 892, 36, 584, 159, 7091, 201]\n",
      "기존 문장: 보면서 웃지 않는 건 불가능하다\n"
     ]
    }
   ],
   "source": [
    "sample_string = df['document'][21]\n",
    "\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:28:15.411766Z",
     "start_time": "2020-10-22T11:28:15.407949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [26, 4115, 338, 1, 2085, 7764, 259, 452, 294, 3, 8031]\n",
      "기존 문장: 진짜 몰입해서 봤다. 몇 번을 봐도 재미있게 볼 영화!\n"
     ]
    }
   ],
   "source": [
    "sample_string = \"진짜 몰입해서 봤다. 몇 번을 봐도 재미있게 볼 영화!\"\n",
    "\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T11:28:16.469049Z",
     "start_time": "2020-10-22T11:28:16.465470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 ----> 진짜 \n",
      "4115 ----> 몰입해서 \n",
      "338 ----> 봤다\n",
      "1 ----> . \n",
      "2085 ----> 몇 \n",
      "7764 ----> 번을 \n",
      "259 ----> 봐도 \n",
      "452 ----> 재미있게 \n",
      "294 ----> 볼 \n",
      "3 ----> 영화\n",
      "8031 ----> !\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
